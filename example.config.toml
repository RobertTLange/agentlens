# Example AgentLens runtime config.
# Copy to ~/.agentlens/config.toml and edit per machine/workflow.

[scan]
mode = "adaptive"
intervalSeconds = 2
intervalMinMs = 200
intervalMaxMs = 3000
fullRescanIntervalMs = 900000
batchDebounceMs = 120
recentEventWindow = 400
includeMetaDefault = true
statusRunningTtlMs = 300000
statusWaitingTtlMs = 900000

[retention]
strategy = "aggressive_recency"
hotTraceCount = 60
warmTraceCount = 240
maxResidentEventsPerHotTrace = 1200
maxResidentEventsPerWarmTrace = 120
detailLoadMode = "lazy_from_disk"

sessionLogDirectories = [
  { directory = "~/.codex", logType = "codex" },
  { directory = "~/.claude", logType = "claude" },
  { directory = "~/.cursor", logType = "cursor" },
  { directory = "~/.gemini", logType = "gemini" },
  { directory = "~/.local/share/opencode", logType = "opencode" }
]

[sources.codex_home]
name = "codex_home"
enabled = true
roots = ["~/.codex/sessions"]
includeGlobs = ["**/*.jsonl"]
excludeGlobs = []
maxDepth = 8
agentHint = "codex"

[sources.claude_projects]
name = "claude_projects"
enabled = true
roots = ["~/.claude/projects"]
includeGlobs = ["**/*.jsonl"]
excludeGlobs = []
maxDepth = 8
agentHint = "claude"

[sources.claude_history]
name = "claude_history"
enabled = false
roots = ["~/.claude"]
includeGlobs = ["history.jsonl"]
excludeGlobs = []
maxDepth = 2
agentHint = "claude"

[sources.cursor_agent_transcripts]
name = "cursor_agent_transcripts"
enabled = false
roots = ["~/.cursor/projects"]
includeGlobs = ["**/agent-transcripts/*.txt"]
excludeGlobs = []
maxDepth = 8
agentHint = "cursor"

[sources.opencode_storage_session]
name = "opencode_storage_session"
enabled = false
roots = ["~/.local/share/opencode/storage/session"]
includeGlobs = ["**/*.json"]
excludeGlobs = []
maxDepth = 8
agentHint = "opencode"

[sources.gemini_tmp]
name = "gemini_tmp"
enabled = false
roots = ["~/.gemini/tmp"]
includeGlobs = ["**/chats/session-*.json", "**/*.jsonl"]
excludeGlobs = []
maxDepth = 8
agentHint = "gemini"

[traceInspector]
includeMetaDefault = false
topModelCount = 3
showAgentBadges = true
showHealthDiagnostics = false

[redaction]
mode = "strict"
alwaysOn = true
replacement = "[REDACTED]"
keyPattern = "(?i)(api[_-]?key|token|secret|password|passphrase|private[_-]?key|access[_-]?key|auth|credential|session|cookie)"
valuePattern = "(?i)(sk-[a-z0-9_-]+|ghp_[a-z0-9]+|AKIA[0-9A-Z]{16}|AIza[0-9A-Za-z\\-_]{20,}|xox[baprs]-[A-Za-z0-9-]+|-----BEGIN [A-Z ]+ PRIVATE KEY-----)"

[cost]
enabled = true
currency = "USD"
unknownModelPolicy = "n_a"

[[cost.modelRates]]
model = "gpt-5.2-codex"
inputPer1MUsd = 1.5
cachedReadPer1MUsd = 0.375
cachedCreatePer1MUsd = 0.375
outputPer1MUsd = 6
reasoningOutputPer1MUsd = 0

[[cost.modelRates]]
model = "gpt-5.3-codex"
inputPer1MUsd = 1.5
cachedReadPer1MUsd = 0.375
cachedCreatePer1MUsd = 0.375
outputPer1MUsd = 6
reasoningOutputPer1MUsd = 0

[[cost.modelRates]]
model = "gpt-5.2"
inputPer1MUsd = 1.75
cachedReadPer1MUsd = 0.175
cachedCreatePer1MUsd = 0.175
outputPer1MUsd = 14
reasoningOutputPer1MUsd = 0

[[cost.modelRates]]
model = "claude-opus-4-5-20251101"
inputPer1MUsd = 5
cachedReadPer1MUsd = 0.5
cachedCreatePer1MUsd = 6.25
outputPer1MUsd = 25
reasoningOutputPer1MUsd = 0

[[cost.modelRates]]
model = "claude-opus-4-6"
inputPer1MUsd = 5
cachedReadPer1MUsd = 0.5
cachedCreatePer1MUsd = 6.25
outputPer1MUsd = 25
reasoningOutputPer1MUsd = 0

[[cost.modelRates]]
model = "claude-sonnet-4-5-20250929"
inputPer1MUsd = 3
cachedReadPer1MUsd = 0.3
cachedCreatePer1MUsd = 3.75
outputPer1MUsd = 15
reasoningOutputPer1MUsd = 0

[[cost.modelRates]]
model = "claude-haiku-4-5-20251001"
inputPer1MUsd = 1
cachedReadPer1MUsd = 0.1
cachedCreatePer1MUsd = 1.25
outputPer1MUsd = 5
reasoningOutputPer1MUsd = 0

[models]
defaultContextWindowTokens = 200000
contextWindows = [
  { model = "gpt-5.2-codex", contextWindowTokens = 400000 },
  { model = "gpt-5.3-codex", contextWindowTokens = 400000 },
  { model = "gpt-5.2", contextWindowTokens = 400000 },
  { model = "claude-opus-4-5-20251101", contextWindowTokens = 200000 },
  { model = "claude-opus-4-6", contextWindowTokens = 200000 },
  { model = "claude-sonnet-4-5-20250929", contextWindowTokens = 200000 },
  { model = "claude-haiku-4-5-20251001", contextWindowTokens = 200000 }
]
